{
  "recordTypeMap": {},
  "RecordSetBundles": [
    {
      "Records": [
        {
          "attributes": {
            "type": "copado__Function__c",
            "url": "/services/data/v61.0/sobjects/copado__Function__c/a0oUB000001K7snYAC"
          },
          "copado__ApexClass__c": "cmcSf.DataSetDeployFunctionCallback",
          "copado__API_Name__c": "SFDX_Data_Set",
          "copado__Callback_Type__c": "ApexClass",
          "copado__Image_Name__c": "copado-function-core:v1",
          "copado__Options__c": "[ ]",
          "copado__Parameters__c": "[ {\n  \"required\" : true,\n  \"name\" : \"sourceOrgId\",\n  \"defaultValue\" : \"{$Source.Id}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceInstanceUrl\",\n  \"defaultValue\" : \"{$Source.Credential.EndpointURL}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"sourceSessionId\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationOrgId\",\n  \"defaultValue\" : \"{$Destination.Id}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationInstanceUrl\",\n  \"defaultValue\" : \"{$Destination.Credential.EndpointURL}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"destinationSessionId\",\n  \"defaultValue\" : \"{$Destination.Credential.SessionId}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"dataJson\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson__c}\"\n}, {\n  \"required\" : true,\n  \"name\" : \"maxBuffer\",\n  \"defaultValue\" : \"5242880\"\n}, {\n  \"required\" : true,\n  \"name\" : \"pollInterval\",\n  \"defaultValue\" : \"5000\"\n}, {\n  \"required\" : false,\n  \"name\" : \"continueOnErrorOption\",\n  \"defaultValue\" : \"{$Context.Apex.cmcSf.GetDataTemplateContinueOnError}\"\n} ]",
          "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForDataDeploy",
          "copado__Script__c": "#!/usr/bin/env node\n\n'use strict';\n\n/**\n * Performs deployment of data based on the data template details provided as input\n * Returns (If ACTION success) the data records are successfully inserted/upserted from the source to the destination org\n * (If ACTION failed) Returns details with error status on the result record\n * @param sourceOrgId\n * @param sourceInstanceUrl\n * @param sourceSessionId\n * @param destinationOrgId\n * @param destinationInstanceUrl\n * @param destinationSessionId\n * @param maxBuffer\n * @param dataJson\n * @param pollInterval\n * @param isTest\n * @param continueOnErrorOption\n */\n\nconst child_process = require('child_process'),\n    fs = require('fs'),\n    {\n        sourceOrgId,\n        sourceInstanceUrl,\n        sourceSessionId,\n        destinationOrgId,\n        destinationInstanceUrl,\n        destinationSessionId,\n        dataJson,\n        maxBuffer,\n        CF_BACKEND_ENDPOINT,\n        pollInterval,\n        isTest,\n        continueOnErrorOption\n    } = process.env,\n    response = {\n        STATUS: {\n            REQUEST_ACCEPTED: 'REQUEST_ACCEPTED',\n            FAILED: 'FAILED',\n            COMPLETED: 'COMPLETED'\n        },\n        TYPE: {\n            JSON: 'json',\n            BUFFER: 'buffer'\n        }\n    },\n    request = {\n        GET: 'GET',\n        POST: 'POST'\n    },\n    TEMP_DIRECTORY = getPath('/tmp'),\n    RESULT_ZIP_FILE_PATH = `${TEMP_DIRECTORY}/deploymentResult.zip`,\n    DATA_DEPLOYMENT_RESULT_DIR = `${TEMP_DIRECTORY}/result`,\n    MAXBUFFER = parseInt(maxBuffer),\n    RESULT_INFO = {\n        LEVEL: {\n            INFO: 'INFO',\n            ERROR: 'ERROR',\n            WARN: 'WARN'\n        },\n        CATEGORY: {\n            UNKNOWN_EXCEPTION: 'Unknown Exception',\n            COPADO_INFO: 'Copado Info',\n            COPADO_SERVICE: 'Copado Service',\n            FILE_SYSTEM: 'File System'\n        },\n        ADDITIONAL_INFORMATION: {\n            POPULATE_INFO_ON_RESULT: 'Populate Information on the result record',\n            EXTRACT_DATA_DEPLOYMENT_RESULT: 'Extract Data Deployment Result',\n            UPLOAD_FILES: 'Upload Files'\n        }\n    },\n    STDIO = {\n        INHERIT: 'inherit'\n    },\n    FILE_NAMES = {\n        RESULT_VIEWER: 'ResultViewer.json',\n        DEPLOYMENT_SUMMARY_JSON: 'deployment_summary.json',\n        DEPLOYMENT_SUMMARY_VIEWER: 'DeploymentSummaryViewer.json'\n    },\n    HEADER_ICON = {\n        RESULT_VIEWER: 'standard:note',\n        DEPLOYMENT_SUMMARY_VIEWER: 'standard:picklist_type'\n    },\n    resultViewerJson = [],\n    CUSTOM_ERROR = {\n        COMMAND_EXECUTION_ERROR: 'CommandExecutionError'\n    },\n    CONTINUE_ON_ERROR = {\n        STOP_DEPLOYMENT_ON_FIRST_ISSUE: 'Stop deployment on first issue'\n    };\nconst TABLE_COLUMNS = {\n    RESULT_VIEWER: [\n\t\t{\n            label: 'Level',\n            fieldName: 'Level',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Level',\n            initialWidth: 80\n        },\n        {\n            label: 'Category',\n            fieldName: 'Category',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Category',\n            initialWidth: 120\n        },\n        {\n            label: 'Additional Information',\n            fieldName: 'AdditionalInformation',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Additional_Information',\n            initialWidth: 200\n        },\n        {\n            label: 'Message',\n            fieldName: 'Message',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'Message'\n        }\n    ],\n    DEPLOYMENT_SUMMARY_VIEWER: [\n\t\t{\n            label: 'Template Name',\n            fieldName: 'templateUrl',\n            type: 'url',\n            typeAttributes: {\n                label: {\n                    fieldName: 'templateName'\n                }\n            },\n            customLabel: 'Template_Name',\n            hideDefaultActions: true\n        },\n        {\n            label: 'SObject',\n            fieldName: 'objectName',\n            type: 'text',\n            wrapText: true,\n            customLabel: 'SObject',\n            hideDefaultActions: true\n        },\n        {\n            label: 'Total',\n            fieldName: 'totalRecords',\n            type: 'number',\n            wrapText: true,\n            customLabel: 'Total',\n            hideDefaultActions: true,\n            initialWidth: 100\n        },\n        {\n            label: 'Failed',\n            fieldName: 'failedRecords',\n            type: 'number',\n            wrapText: true,\n            customLabel: 'Failed',\n            hideDefaultActions: true,\n            initialWidth: 100\n        },\n        {\n            label: 'Generated Ids',\n            fieldName: 'generatedIds',\n            type: 'number',\n            wrapText: true,\n            customLabel: 'Generated_Ids',\n            hideDefaultActions: true,\n            initialWidth: 120\n        }\n    ]\n};\nconst HEADER = {\n    RESULT_VIEWER: {\n        label: 'Execution Details',\n        customLabel: 'Execution_Details'\n    },\n    DEPLOYMENT_SUMMARY_VIEWER: {\n        label: 'Data Deployment Result',\n        customLabel: 'Data_Deployment_Result'\n    }\n};\nconst CSV_COLUMN = {\n    label: 'CSV File',\n    fieldName: 'csvFileLink',\n    type: 'button-icon',\n    typeAttributes: {\n        iconName: {\n            fieldName: 'csvFileIcon'\n        },\n        disabled: {\n            fieldName: 'isCsvFileIconDisabled'\n        },\n        type: 'url',\n        fieldName: 'csvFileLink',\n        variant: 'bare'\n    },\n    wrapText: true,\n    customLabel: 'CSV_File',\n    hideDefaultActions: true,\n    initialWidth: 80\n};\n\nlet executionError;\n\nasync function execute() {\n    try {\n        // extract data\n        const dataJsonPayload = JSON.parse(dataJson);\n\n        const dataTemplateId = dataJsonPayload.dataTemplateId;\n        const queryFilterList = dataJsonPayload.queryFilterList;\n        const filterLogic = dataJsonPayload.filterLogic;\n        const continueOnError = continueOnErrorOption ? continueOnErrorOption : dataJsonPayload.continueOnError;\n\n        const sourceDataSetId = dataJsonPayload.sourceDataSetId;\n        const destinationDataSetId = dataJsonPayload.destinationDataSetId;\n        const commitMessage = dataJsonPayload.commitMessage ? dataJsonPayload.commitMessage : null;\n        // main process\n        const apiPayload = this.populateCredentialsValues(\n            sourceDataSetId,\n            destinationDataSetId,\n            dataTemplateId,\n            queryFilterList,\n            filterLogic,\n            commitMessage\n        );\n\n        const deploymentId = await this.initiateDataDeployment(apiPayload);\n        this.logger('Deployment Id', deploymentId);\n        await this.pollDataDeploymentStatus(deploymentId);\n\n        // depend on type of process: generate/deploy. There will be different table columns needed\n        this.configureResultColumn(sourceDataSetId, destinationDataSetId);\n        await this.downloadDataDeploymentResult(deploymentId);\n        this.uploadDataDeploymentInfoOnResult(continueOnError, sourceDataSetId, destinationDataSetId);\n    } catch (err) {\n        this.logger('Error stack', err.stack);\n        if (!(err instanceof CommandExecutionError)) {\n            this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, RESULT_INFO.CATEGORY.UNKNOWN_EXCEPTION, `See logs for more info`, err.message);\n        }\n        executionError = err.message || err?.toString() || `Unknown Error occurred`;\n    } finally {\n        if (resultViewerJson?.length) {\n            this.uploadResultTableJson(\n                resultViewerJson,\n                TABLE_COLUMNS.RESULT_VIEWER,\n                FILE_NAMES.RESULT_VIEWER,\n                HEADER.RESULT_VIEWER,\n                HEADER_ICON.RESULT_VIEWER\n            );\n        }\n        if (executionError) {\n            this.executeCommand(\n                this.getErrorCmdString(executionError),\n                RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                RESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n            );\n            process.exit(1);\n        }\n    }\n}\n\nfunction parseDatatemplate(dataTemplateDetail) {\n    try {\n        const payload = JSON.parse(dataTemplateDetail);\n        this.setPayloadDataLimit(payload);\n        return payload;\n    } catch (error) {\n        // Added logs to debug the payload in case of an error\n        this.logger('Data Template Detail', dataTemplateDetail);\n        throw new Error('The input data template information is not a valid JSON');\n    }\n}\n\n// To replace all limitValue field (if exist) by limit field\nfunction setPayloadDataLimit(payload) {\n    payload.main_template['limit'] = payload.main_template['limitValue'];\n    delete payload.main_template['limitValue'];\n    payload.related_templates?.forEach(template => {\n        template['limit'] = template['limitValue'];\n        delete template['limitValue'];\n    });\n}\n\nfunction populateCredentialsValues(sourceDataSetId, destinationDataSetId, dataTemplateId, queryFilterList, filterLogic, commitMessage) {\n    const source = {\n        organizationId: sourceOrgId,\n        instance: sourceInstanceUrl,\n        token: sourceSessionId\n    };\n    const destination = {\n        organizationId: destinationOrgId,\n        instance: destinationInstanceUrl,\n        token: destinationSessionId\n    };\n\n    if (sourceDataSetId && sourceDataSetId.trim().length > 0 && !destinationDataSetId) {\n        source.datasetRecordId = sourceDataSetId.trim();\n        source.instance = process.env.CF_SF_ENDPOINT;\n        source.token = process.env.CF_SF_SESSIONID;\n    } else if (destinationDataSetId && destinationDataSetId.trim().length > 0 && !sourceDataSetId) {\n        destination.datasetRecordId = destinationDataSetId.trim();\n        destination.instance = process.env.CF_SF_ENDPOINT;\n        destination.token = process.env.CF_SF_SESSIONID;\n    } else {\n        throw new Error('The input data for the function is invalid. Dataset Id can be on either source or destination, not both');\n    }\n\n    const dataTemplate =\n        (destinationDataSetId && destinationDataSetId.trim().length > 0 && !sourceDataSetId) ?\n        this.getDataTemplateInfo(dataTemplateId, queryFilterList, filterLogic, destinationOrgId) :\n        null;\n\n    const result = {\n        commitMessage,\n        org_credentials: {\n            source,\n            destination\n        },\n        dataTemplate\n    };\n    return result;\n}\n\nasync function initiateDataDeployment(payload) {\n    const result = await this.sendRequest('/ddapi/data_deploy', request.POST, response.TYPE.JSON, payload);\n    // Added logs to debug in case of unprecedented response from the api\n    this.asyncCopadoLogMessage('Initiate data set Process');\n    if (!result?.deploymentId) {\n        throw new Error(`${result.status} - ${result.errorMessage ? result.errorMessage : result.error}`);\n    }\n    return result.deploymentId;\n}\n\nfunction pollDataDeploymentStatus(deploymentId) {\n    return new Promise((resolve, reject) => {\n        this.asyncCopadoLogMessage('Polling data set process status');\n        const pollDeploymentStatus = setInterval(async () => {\n            const result = await this.sendRequest(`/ddapi/data_job/${deploymentId}/status`, request.GET, response.TYPE.JSON);\n            // Adding debug to track progress in logs\n            switch (result.status) {\n                case response.STATUS.FAILED:\n                    clearInterval(pollDeploymentStatus);\n                    reject(new Error(result.step));\n                    break;\n                case response.STATUS.COMPLETED:\n                    this.asyncCopadoLogMessage(result.step);\n                    clearInterval(pollDeploymentStatus);\n                    resolve();\n                    break;\n                default:\n                    this.asyncCopadoLogMessage(result.step);\n            }\n        }, pollInterval);\n    });\n}\n\nfunction configureResultColumn(sourceDataSetId, destinationDataSetId) {\n    // Deploy data set\n    if (sourceDataSetId && sourceDataSetId.trim().length > 0 && !destinationDataSetId) {\n        HEADER.DEPLOYMENT_SUMMARY_VIEWER.label = 'Data Set Deployment Result';\n        HEADER.DEPLOYMENT_SUMMARY_VIEWER.customLabel = 'Data_Set_Deployment_Result';\n        TABLE_COLUMNS.DEPLOYMENT_SUMMARY_VIEWER.push(CSV_COLUMN);\n    }\n    // Generate data set\n    else if (destinationDataSetId && destinationDataSetId.trim().length > 0 && !sourceDataSetId) {\n        HEADER.DEPLOYMENT_SUMMARY_VIEWER.label = 'Data Set Generation Result';\n        HEADER.DEPLOYMENT_SUMMARY_VIEWER.customLabel = 'Data_Set_Generation_Result';\n    }\n}\n\nasync function downloadDataDeploymentResult(deploymentId) {\n    this.asyncCopadoLogMessage('Downloading data set process result');\n    const result = await this.sendRequest(`/ddapi/data_job/${deploymentId}/result`, request.GET, response.TYPE.BUFFER);\n    fs.writeFileSync(RESULT_ZIP_FILE_PATH, result);\n    this.executeCommand(\n        `unzip -d ${DATA_DEPLOYMENT_RESULT_DIR} ${RESULT_ZIP_FILE_PATH}`,\n        RESULT_INFO.CATEGORY.FILE_SYSTEM,\n        RESULT_INFO.ADDITIONAL_INFORMATION.EXTRACT_DATA_DEPLOYMENT_RESULT\n    );\n}\n\nasync function sendRequest(path, method, responseType, payload) {\n    let result;\n    try {\n        const apiResponse = await fetch(CF_BACKEND_ENDPOINT + path, this.getOptions(method, payload));\n        switch (responseType) {\n            case response.TYPE.BUFFER:\n                result = Buffer.from(await apiResponse.arrayBuffer());\n                break;\n            case response.TYPE.JSON:\n                result = await apiResponse.json();\n                break;\n            default:\n                result = await apiResponse.text();\n        }\n    } catch (error) {\n        throw new Error(`ERROR: ${method} ${path} : ${error}`);\n    }\n    return result;\n}\n\nfunction getOptions(method, payload) {\n    const options = {\n        method: method,\n        headers: {\n            'Content-Type': 'application/json'\n        }\n    };\n    if (method === request.POST) {\n        options.body = JSON.stringify(payload);\n    }\n    return options;\n}\n\nfunction uploadDataDeploymentInfoOnResult(continueOnError, sourceDataSetId, destinationDataSetId) {\n    this.asyncCopadoLogMessage('Uploading data set process detail files on the result record');\n\n    fs.readdirSync(DATA_DEPLOYMENT_RESULT_DIR, {\n        encoding: 'utf-8'\n    })?.forEach(file => {\n        this.populateResultViewer(\n            RESULT_INFO.LEVEL.INFO,\n            RESULT_INFO.CATEGORY.COPADO_SERVICE,\n            RESULT_INFO.ADDITIONAL_INFORMATION.UPLOAD_FILES,\n            `${DATA_DEPLOYMENT_RESULT_DIR}/${file}`\n        );\n        this.executeCommand(`copado --uploadfile '${DATA_DEPLOYMENT_RESULT_DIR}/${file}'`);\n    });\n\n    let deploymentSummary = this.getDeploymentSummary(`${DATA_DEPLOYMENT_RESULT_DIR}/${FILE_NAMES.DEPLOYMENT_SUMMARY_JSON}`);\n    this.addTotalRecordInfo(deploymentSummary);\n    this.uploadResultTableJson(\n        deploymentSummary,\n        TABLE_COLUMNS.DEPLOYMENT_SUMMARY_VIEWER,\n        FILE_NAMES.DEPLOYMENT_SUMMARY_VIEWER,\n        HEADER.DEPLOYMENT_SUMMARY_VIEWER,\n        HEADER_ICON.DEPLOYMENT_SUMMARY_VIEWER\n    );\n\n    const resultData = this.getResultData(deploymentSummary);\n\n    if (resultData) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_SERVICE, 'Updating data set process info', resultData);\n        this.executeCommand(\n            `copado -p 'Updating data set process info' -r '${resultData}'`,\n            RESULT_INFO.CATEGORY.COPADO_SERVICE,\n            RESULT_INFO.ADDITIONAL_INFORMATION.POPULATE_INFO_ON_RESULT\n        );\n    }\n\n    // check option continueOnError when deploy dataset\n    if (\n        sourceDataSetId &&\n        sourceDataSetId.trim().length > 0 &&\n        !destinationDataSetId &&\n        continueOnError == CONTINUE_ON_ERROR.STOP_DEPLOYMENT_ON_FIRST_ISSUE\n    ) {\n        checkDeploymentSummary(deploymentSummary);\n    }\n}\n\nfunction checkDeploymentSummary(deploymentSummary) {\n    if (deploymentSummary?.length > 0) {\n        deploymentSummary.forEach(result => {\n            if (result.failedRecords > 0) {\n                throw new Error('Some deployed records failed. Find more information in result files');\n            }\n        });\n    }\n}\n\nfunction getDeploymentSummary(filePath) {\n    let result = '';\n    if (fs.existsSync(filePath)) {\n        const fileData = fs.readFileSync(filePath, 'utf-8');\n        if (fileData) {\n            result = JSON.parse(fileData);\n        }\n    }\n    return result;\n}\n\nfunction getResultData(deploymentSummary) {\n    let result = '';\n    if (deploymentSummary) {\n        result = deploymentSummary\n            .map(templateDeploymentResult =>\n                Object.keys(templateDeploymentResult)\n                .map(key => `${key} : ${templateDeploymentResult[key]}`)\n                .join('\\n')\n            )\n            .join('\\n------------------------\\n');\n        result =\n            'To find more info related to the data set process result, please look at the deployment_summary.json attached to this result record\\n' +\n            result;\n    }\n    return result?.substring(0, 131070); // truncating the string to prevent the length from exceeding Long Text Area(131072) size limit\n}\n\nfunction addTotalRecordInfo(deploymentSummary) {\n    deploymentSummary.forEach(summary => {\n        summary.totalRecords = summary.deployedRecords + summary.failedRecords;\n    });\n}\n\nfunction getErrorCmdString(error) {\n    const suffix = 'Please check the logs for details.';\n    return `copado -p 'Error' -e \"${error?.substring(0, 32765)}. ${suffix}\"`;\n}\n\nfunction getPath(filePath) {\n    return isTest ? `${__dirname}/__tests__/__mockDir__${filePath}` : filePath;\n}\n\nfunction executeCommand(command, category, additionalnfo, hasJsonResponse) {\n    let errorMessage;\n    const options = {\n        shell: true,\n        maxBuffer: MAXBUFFER\n    };\n    const response = child_process.spawnSync(command, options);\n    const {\n        outputStream,\n        errorStream\n    } = this.log(response);\n    if (response?.status == 0) {\n        return hasJsonResponse ? JSON.parse(outputStream) : outputStream;\n    }\n    if (!hasJsonResponse) {\n        errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n    } else {\n        try {\n            return JSON.parse(outputStream);\n        } catch (error) {\n            errorMessage = errorStream ? errorStream : `Error executing the command ${command}`;\n        }\n    }\n    if (errorMessage) {\n        this.populateResultViewer(RESULT_INFO.LEVEL.ERROR, category, additionalnfo, errorMessage);\n        throw new CommandExecutionError(errorMessage);\n    }\n}\n\nfunction log(response) {\n    const outputStream = response?.stdout?.toString().trim();\n    const errorStream = response?.stderr?.toString().trim();\n    if (outputStream) {\n        this.logger('Stream log', outputStream);\n    }\n    if (errorStream) {\n        this.logger('Stream log', errorStream);\n    }\n    return {\n        outputStream,\n        errorStream\n    };\n}\n\nfunction asyncCopadoLogMessage(msg, level) {\n    this.populateResultViewer(level ? level : RESULT_INFO.LEVEL.INFO, RESULT_INFO.CATEGORY.COPADO_INFO, '', msg);\n    new Promise(resolve => {\n        child_process.exec(`copado -p \"${msg}\"`, {\n            stdio: STDIO.INHERIT\n        }, () => {\n            resolve();\n        });\n    });\n}\n\nfunction populateResultViewer(level, category, additionalInfo, message) {\n    resultViewerJson.push({\n        Level: level,\n        Category: category,\n        Message: message,\n        AdditionalInformation: additionalInfo\n    });\n}\n\nfunction uploadResultTableJson(data, columns, fileName, header, headerIcon) {\n    const RESULT_VIEWER_JSON_PATH = `${TEMP_DIRECTORY}/${fileName}`;\n\n    const fileContent = {\n        data,\n        columns,\n        header,\n        headerIcon\n    };\n    fs.writeFileSync(RESULT_VIEWER_JSON_PATH, JSON.stringify(fileContent, null, 2));\n    this.uploadFileAtPath(RESULT_VIEWER_JSON_PATH);\n}\n\nfunction uploadFileAtPath(filePath) {\n    new Promise((resolve, reject) => {\n        child_process.exec(`copado --uploadfile ${filePath}`, {}, (error, stdout, stderr) => {\n            if (error?.code) {\n                const errorResponse = stderr ? stderr : `Error executing the command : ${error?.cmd}`;\n                this.populateResultViewer(\n                    RESULT_INFO.LEVEL.ERROR,\n                    RESULT_INFO.CATEGORY.COPADO_SERVICE,\n                    `Uploading file at ${filePath}`,\n                    errorResponse\n                );\n                reject(new CommandExecutionError(errorResponse));\n            } else {\n                resolve();\n            }\n        });\n    });\n}\n\nfunction logger(label, info) {\n    console.log(label, ': ', info);\n}\n\nclass CommandExecutionError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = CUSTOM_ERROR.COMMAND_EXECUTION_ERROR;\n    }\n}\n\nfunction getDataTemplateInfo(dataTemplateId, queryFilterList, filterLogic, dataTemplateEnvId) {\n    if (!dataTemplateId) {\n        throw new Error('Data template ID is empty');\n    }\n    const dataTemplate = {\n        dataTemplateId,\n        copadoOrg: {\n            organizationId: dataTemplateEnvId,\n            instance: process.env.CF_SF_ENDPOINT,\n            token: process.env.CF_SF_SESSIONID\n        },\n        filterLogic: filterLogic,\n        queryFilterList: queryFilterList\n    };\n    return dataTemplate;\n}\n\nmodule.exports.initiateDataDeployment = initiateDataDeployment;\nmodule.exports.pollDataDeploymentStatus = pollDataDeploymentStatus;\nmodule.exports.populateCredentialsValues = populateCredentialsValues;\nmodule.exports.downloadDataDeploymentResult = downloadDataDeploymentResult;\nmodule.exports.sendRequest = sendRequest;\nmodule.exports.getOptions = getOptions;\nmodule.exports.uploadDataDeploymentInfoOnResult = uploadDataDeploymentInfoOnResult;\nmodule.exports.getErrorCmdString = getErrorCmdString;\nmodule.exports.getPath = getPath;\nmodule.exports.executeCommand = executeCommand;\nmodule.exports.log = log;\nmodule.exports.execute = execute;\nmodule.exports.getResultData = getResultData;\nmodule.exports.parseDatatemplate = parseDatatemplate;\nmodule.exports.setPayloadDataLimit = setPayloadDataLimit;\nmodule.exports.logger = logger;\nmodule.exports.asyncCopadoLogMessage = asyncCopadoLogMessage;\nmodule.exports.populateResultViewer = populateResultViewer;\nmodule.exports.uploadResultTableJson = uploadResultTableJson;\nmodule.exports.getDeploymentSummary = getDeploymentSummary;\nmodule.exports.uploadFileAtPath = uploadFileAtPath;\nmodule.exports.CommandExecutionError = CommandExecutionError;\nmodule.exports.configureResultColumn = configureResultColumn;\nmodule.exports.addTotalRecordInfo = addTotalRecordInfo;\nmodule.exports.getDataTemplateInfo = getDataTemplateInfo;\nmodule.exports.checkDeploymentSummary = checkDeploymentSummary;\n\n!isTest && this.execute();",
          "copado__Type__c": "Standard",
          "copado__Worker_Size__c": "S",
          "Id": "a0oUB000001K7snYAC",
          "LastReferencedDate": "2024-07-23T05:57:12.000+0000",
          "LastViewedDate": "2024-07-23T05:57:12.000+0000",
          "Name": "SFDX Data Set"
        },
        {
          "attributes": {
            "type": "copado__Function__c",
            "url": "/services/data/v63.0/sobjects/copado__Function__c/a0oUB000004u1ITYAY"
          },
          "copado__API_Name__c": "SFDX_Data_Devops_Retrieve",
          "copado__Image_Name__c": "copado-multicloud-dx:v5",
          "copado__Options__c": "[ ]",
          "copado__Parameters__c": "[ {\n  \"name\" : \"LWC_PAYLOAD\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.payload}\"\n}, {\n  \"name\" : \"RECORD_ID\",\n  \"defaultValue\" : \"{$Context.JobExecution__r.DataJson.userStoryId}\"\n}, {\n  \"name\" : \"SOURCE_INSTANCE\",\n  \"defaultValue\" : \"{$Source.Credential.Endpoint}\"\n}, {\n  \"name\" : \"SOURCE_TOKEN\",\n  \"defaultValue\" : \"{$Source.Credential.SessionId}\"\n} ]",
          "copado__Script__c": "#!/usr/bin/env node\n\"use strict\";\n\nconst fs = require(\"fs\");\nconst child_process = require(\"child_process\");\nconst { execSync } = child_process;\n\nconst {\n  CF_BACKEND_ENDPOINT,\n  CF_SF_ENDPOINT,\n  CF_SF_SESSIONID,\n  pollInterval = 3000,\n  maxBuffer = 10485760,\n  LWC_PAYLOAD,\n  RECORD_ID,\n  SOURCE_INSTANCE,\n  SOURCE_TOKEN\n} = process.env;\n\nconst TIMEOUT_MS = parseInt(pollInterval, 10) || 3000;\n\n// -- MAIN EXECUTION FUNCTION -- //\nasync function execute() {\n  try {\n    const payload = JSON.parse(LWC_PAYLOAD);\n    \n    payload.orgCredentials = {\n      sourceOrgCredentials: {\n        instance: SOURCE_INSTANCE,\n        token: SOURCE_TOKEN,\n        targetRecordId: null\n      },\n      responseOrgCredentials: {\n        instance: CF_SF_ENDPOINT,\n        token: CF_SF_SESSIONID,\n        targetRecordId: RECORD_ID\n      }\n    };\n\n    const deploymentId = await initiateDataRetrieval(payload);\n    await pollDataRetrievalStatus(deploymentId, payload.orgCredentials.sourceOrgCredentials.instance);\n\n  } catch (error) {\n    execSync(`copado -p \"Error\" -e \"${error.message || error}\"`);\n    process.exit(1);\n  }\n}\n\n// -- POST the LWC payload to /data_retrieval -- //\nasync function initiateDataRetrieval(payload) {\n  execSync(`copado -p \"Starting data retrieval\"`);\n  \n  const path = \"/ddapi/data_retrieval\";\n  const response = await sendRequest(path, \"POST\", \"json\", payload);\n\n  if (!response || !response.deploymentId) {\n    throw new Error(\n      `No deploymentId returned from ${path}: ${JSON.stringify(response)}`\n    );\n  }\n  \n  return response.deploymentId;\n}\n\n// -- Poll /data_job/{deploymentId}/status -- //\nfunction pollDataRetrievalStatus(deploymentId, sourceSessionUrl) {\n  return new Promise((resolve, reject) => {\n    const intervalId = setInterval(async () => {\n      try {\n        const statusPath = `/ddapi/data_job/${deploymentId}/status`;\n        const statusResponse = await sendRequest(statusPath, \"GET\", \"json\");\n        const currentStatus = statusResponse?.status;\n\n        if (!currentStatus) {\n          throw new Error(\n            `Invalid status response: ${JSON.stringify(statusResponse)}`\n          );\n        }\n\n        switch (currentStatus) {\n          case \"FAILED\":\n            clearInterval(intervalId);\n            return reject(\n              new Error(\n                statusResponse.step || \"Data retrieval returned FAILED status\"\n              )\n            );\n          case \"COMPLETED\":\n          \tconst result = { deploymentId, sourceSessionUrl };\n          \texecSync(`copado -p \"${statusResponse.step}\" -r '${JSON.stringify(result)}'`);\n            clearInterval(intervalId);\n            return resolve();\n          default:\n          \texecSync(`copado -p \"${statusResponse.step}\"`);\n            break;\n        }\n      } catch (err) {\n        clearInterval(intervalId);\n        return reject(err);\n      }\n    }, TIMEOUT_MS);\n  });\n}\n\n// -- Generic fetch wrapper: supports JSON or BUFFER response -- //\nasync function sendRequest(endpointPath, method, responseType, payload) {\n  const url = CF_BACKEND_ENDPOINT + endpointPath;\n\n  const options = {\n    method,\n    headers: { \"Content-Type\": \"application/json\" }\n  };\n  \n  if (method === \"POST\" && payload) {\n    options.body = JSON.stringify(payload);\n  }\n\n  try {\n    const resp = await fetch(url, options);\n    \n    if (!resp.ok) {\n      throw new Error(\n        `HTTP ${resp.status} - ${resp.statusText} from ${method} ${url}`\n      );\n    }\n    \n    switch (responseType) {\n      case \"buffer\":\n        return Buffer.from(await resp.arrayBuffer());\n      case \"json\":\n        return await resp.json();\n      default:\n        return await resp.text();\n    }\n  } catch (error) {\n    throw new Error(error);\n  }\n}\n\n// -- Run the script if not in test mode -- //\nif (require.main === module) {\n  execute();\n}\n\nmodule.exports = {\n  execute,\n  initiateDataRetrieval,\n  pollDataRetrievalStatus,\n  sendRequest\n};",
          "copado__Type__c": "Standard",
          "copado__Worker_Size__c": "S",
          "Id": "a0oUB000004u1ITYAY",
          "LastReferencedDate": "2025-02-28T11:10:47.000+0000",
          "LastViewedDate": "2025-02-28T11:10:47.000+0000",
          "Name": "SFDX Data Devops Retrieve"
        }
      ],
      "ObjectType": "copado__Function__c"
    },
    {
      "Records": [
        {
          "attributes": {
            "type": "copado__JobTemplate__c",
            "url": "/services/data/v61.0/sobjects/copado__JobTemplate__c/a0xUB000000IjRhYAK"
          },
          "copado__ApiName__c": "SFDX_Generate_Data_Set_1",
          "copado__Type__c": "Standard",
          "copado__Version__c": 1,
          "Id": "a0xUB000000IjRhYAK",
          "LastReferencedDate": "2024-07-23T06:01:50.000+0000",
          "LastViewedDate": "2024-07-23T06:01:50.000+0000",
          "Name": "SFDX Generate Data Set"
        },
        {
          "attributes": {
            "type": "copado__JobTemplate__c",
            "url": "/services/data/v61.0/sobjects/copado__JobTemplate__c/a0xUB000000JNddYAG"
          },
          "copado__ApiName__c": "SFDX_Deploy_Data_Set_1",
          "copado__Type__c": "Standard",
          "copado__Version__c": 1,
          "Id": "a0xUB000000JNddYAG",
          "LastReferencedDate": "2024-07-23T06:04:56.000+0000",
          "LastViewedDate": "2024-07-23T06:04:56.000+0000",
          "Name": "SFDX Deploy Data Set"
        },
        {
          "attributes": {
            "type": "copado__JobTemplate__c",
            "url": "/services/data/v63.0/sobjects/copado__JobTemplate__c/a0xUB000001er0DYAQ"
          },
          "copado__ApiName__c": "SFDX_Data_Devops_Retrieve_1",
          "copado__Type__c": "Standard",
          "copado__Version__c": 1,
          "Id": "a0xUB000001er0DYAQ",
          "LastReferencedDate": "2025-02-28T11:10:55.000+0000",
          "LastViewedDate": "2025-02-28T11:10:55.000+0000",
          "Name": "SFDX Data Devops Retrieve"
        }
      ],
      "ObjectType": "copado__JobTemplate__c"
    },
    {
      "Records": [
        {
          "attributes": {
            "type": "copado__JobStep__c",
            "url": "/services/data/v61.0/sobjects/copado__JobStep__c/a0wUB000000MjrJYAS"
          },
          "copado__ApiName__c": "Generate_Data_Set_Job_Template_1_Run_sfdx_data_set_function_1",
          "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Data_Set\",\"parameters\":[{\"name\":\"sourceOrgId\",\"value\":\"{$Source.Id}\",\"required\":true},{\"name\":\"sourceInstanceUrl\",\"value\":\"{$Source.Credential.EndpointURL}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"destinationOrgId\",\"value\":\"{$Destination.Id}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.EndpointURL}\",\"required\":true},{\"name\":\"destinationSessionId\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"dataJson\",\"value\":\"{$Context.JobExecution__r.DataJson__c}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\",\"required\":true},{\"name\":\"pollInterval\",\"value\":\"5000\",\"required\":true},{\"name\":\"continueOnErrorOption\",\"value\":\"{$Context.Apex.cmcSf.GetDataTemplateContinueOnError}\",\"required\":false}]}",
          "copado__CustomType__c": "Function",
          "copado__IsSkipped__c": false,
          "copado__JobTemplate__c": "a0xUB000000IjRhYAK",
          "copado__Order__c": 1,
          "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForDataDeploy",
          "copado__Type__c": "Function",
          "Id": "a0wUB000000MjrJYAS",
          "Name": "Run sfdx generate data set function"
        },
        {
          "attributes": {
            "type": "copado__JobStep__c",
            "url": "/services/data/v61.0/sobjects/copado__JobStep__c/a0wUB000000NXRVYA4"
          },
          "copado__ApiName__c": "SFDX_Deploy_Data_Set_1_Run_sfdx_data_set_function_1",
          "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Data_Set\",\"parameters\":[{\"name\":\"sourceOrgId\",\"value\":\"{$Source.Id}\",\"required\":true},{\"name\":\"sourceInstanceUrl\",\"value\":\"{$Source.Credential.EndpointURL}\",\"required\":true},{\"name\":\"sourceSessionId\",\"value\":\"{$Source.Credential.SessionId}\",\"required\":true},{\"name\":\"destinationOrgId\",\"value\":\"{$Destination.Id}\",\"required\":true},{\"name\":\"destinationInstanceUrl\",\"value\":\"{$Destination.Credential.EndpointURL}\",\"required\":true},{\"name\":\"destinationSessionId\",\"value\":\"{$Destination.Credential.SessionId}\",\"required\":true},{\"name\":\"dataJson\",\"value\":\"{$Context.JobExecution__r.DataJson__c}\",\"required\":true},{\"name\":\"maxBuffer\",\"value\":\"5242880\",\"required\":true},{\"name\":\"pollInterval\",\"value\":\"5000\",\"required\":true},{\"name\":\"continueOnErrorOption\",\"value\":\"{$Context.Apex.cmcSf.GetDataTemplateContinueOnError}\",\"required\":false}]}",
          "copado__CustomType__c": "Function",
          "copado__IsSkipped__c": false,
          "copado__JobTemplate__c": "a0xUB000000JNddYAG",
          "copado__Order__c": 1,
          "copado__Result_Viewer_Component__c": "cmcSf:resultViewerForDataDeploy",
          "copado__Type__c": "Function",
          "Id": "a0wUB000000NXRVYA4",
          "Name": "Run sfdx deploy data set function"
        },
        {
          "attributes": {
            "type": "copado__JobStep__c",
            "url": "/services/data/v63.0/sobjects/copado__JobStep__c/a0wUB0000026vgnYAA"
          },
          "copado__ApiName__c": "SFDX_Data_Devops_Retrieve_1_Run_SFDX_Data_Devops_Retrieve_1",
          "copado__ConfigJson__c": "{\"functionName\":\"SFDX_Data_Devops_Retrieve\",\"parameters\":[{\"name\":\"LWC_PAYLOAD\",\"value\":\"{$Context.JobExecution__r.DataJson.payload}\"},{\"name\":\"RECORD_ID\",\"value\":\"{$Context.JobExecution__r.DataJson.userStoryId}\"},{\"name\":\"SOURCE_INSTANCE\",\"value\":\"{$Source.Credential.Endpoint}\"},{\"name\":\"SOURCE_TOKEN\",\"value\":\"{$Source.Credential.SessionId}\"}]}",
          "copado__CustomType__c": "Function",
          "copado__IsSkipped__c": false,
          "copado__JobTemplate__c": "a0xUB000001er0DYAQ",
          "copado__Order__c": 1,
          "copado__Type__c": "Function",
          "Id": "a0wUB0000026vgnYAA",
          "Name": "Run SFDX Data Devops Retrieve"
        }
      ],
      "ObjectType": "copado__JobStep__c"
    }
  ],
  "blobsByUID": {}
}